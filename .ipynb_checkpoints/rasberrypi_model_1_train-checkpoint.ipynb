{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"\"\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=10\n",
    "im_height, im_width = 224, 224  ## Image input resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### datagenerator to get the batch of data, It takes file list, batch size and resolution as arguments\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class BrainTumorDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True, do_augmentation=False):\n",
    "        \n",
    "        self.df = df\n",
    "        self.batch_size=batch_size\n",
    "        self.input_size=input_size\n",
    "        self.do_augmentation=do_augmentation\n",
    "        if do_augmentation:  ## We need to augment only the training data here.\n",
    "            self.data_augmentation = tf.keras.Sequential([\n",
    "                layers.RandomFlip(\"horizontal\"),\n",
    "                layers.RandomRotation(0.2),\n",
    "                ])\n",
    "\n",
    "            self.replicate_factor=12\n",
    "        else:\n",
    "            self.replicate_factor=1\n",
    "\n",
    "        self.max_index=len(self.df)//self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def load_image(self,name):\n",
    "        image= tf.keras.preprocessing.image.load_img(name)\n",
    "        image= tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image= tf.image.resize(image,(self.input_size[0],self.input_size[1]))\n",
    "        if self.do_augmentation: # and np.random.rand(1)<0.2:   #0.2 propbality the augmentation happens, we don't want distort all the imagews\n",
    "            image=self.data_augmentation(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index=index%self.max_index\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images=[]\n",
    "        labels=[]\n",
    "        for index, row in batches.iterrows():\n",
    "          images.append(self.load_image(row['filename']))\n",
    "          labels.append(row['labels'])\n",
    "        return np.array(images),np.array(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)*self.replicate_factor // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "###### Function to Get the Model\n",
    "\n",
    "def GetModel(type='simple',im_height=224,im_width=224, compile=True):\n",
    "    tf.keras.backend.reset_uids()\n",
    "    if type=='simple':\n",
    "        model = Sequential([\n",
    "          layers.Rescaling(1./255, input_shape=(im_height, im_width, 3)),\n",
    "          layers.Conv2D(8, 3, padding='valid', activation='relu',name='cnn1'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(16, 3, padding='valid', activation='relu',name='cnn2'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='valid', activation='relu',name='cnn3'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(32, activation='relu',name='dense1'),\n",
    "          layers.Dense(1,name='dense2')\n",
    "        ])\n",
    "    elif type=='extra_dense_cnn':\n",
    "        model = Sequential([\n",
    "          layers.Rescaling(1./255, input_shape=(im_height, im_width, 3)),\n",
    "          layers.Conv2D(8, 3, padding='valid', activation='relu',name='cnn1',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(16, 3, padding='valid', activation='relu',name='cnn2',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='valid', activation='relu',name='cnn3',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='same', activation='relu',name='cnn4',trainable=True),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(32, activation='relu',name='dense1'),\n",
    "          layers.Dense(32, activation='relu',name='dense_post'),\n",
    "          layers.Dense(1,name='dense2')\n",
    "        ])\n",
    "    else:\n",
    "      raise 'Model type is not correct'\n",
    "    if compile:\n",
    "      model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "# model_1=GetModel()\n",
    "# for layer in model_1.layers:\n",
    "#   print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " cnn1 (Conv2D)               (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cnn2 (Conv2D)               (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn3 (Conv2D)               (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn4 (Conv2D)               (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_post (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,625\n",
      "Trainable params: 702,593\n",
      "Non-trainable params: 6,032\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " cnn1 (Conv2D)               (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cnn2 (Conv2D)               (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn3 (Conv2D)               (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                692256    \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698,321\n",
      "Trainable params: 698,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.6312 - accuracy: 0.5781 - val_loss: 0.4708 - val_accuracy: 0.7333\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3998 - accuracy: 0.7656 - val_loss: 0.3933 - val_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2682 - accuracy: 0.8906 - val_loss: 0.3363 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.1604 - accuracy: 0.9844 - val_loss: 0.3137 - val_accuracy: 0.8667\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.3315 - val_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=GetModel(type='extra_dense_cnn')\n",
    "base_model=GetModel(type='simple')\n",
    "base_model.load_weights('./checkpoints/main_model/model')\n",
    "base_layer_names = [layer.name for layer in base_model.layers]\n",
    "\n",
    "### Load the weights by name\n",
    "for layer in model.layers:\n",
    "    if layer.name in base_layer_names:\n",
    "        layer.set_weights(base_model.get_layer(layer.name).get_weights())\n",
    "\n",
    "df=pd.read_csv('./brain_tumour_dataset/rasp1_data.csv') \n",
    "train_rasp1,vals_rasp1=train_test_split(df,train_size=0.7, stratify=df['labels'],random_state=52)\n",
    "\n",
    "train_ds= BrainTumorDataset(train_rasp1,8,input_size=(im_height, im_width,3),do_augmentation=False)\n",
    "val_ds =  BrainTumorDataset(vals_rasp1,1,input_size=(im_height, im_width,3))\n",
    "history = model.fit(train_ds,validation_data=val_ds,epochs=nepochs) ## Train and save the rasp1 model\n",
    "\n",
    "model.save_weights('./checkpoints/rasp1_model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2746 - accuracy: 0.9333\n",
      "Accuracy of rasberrypi--1 trained model on unseen data 0.9333333373069763%\n"
     ]
    }
   ],
   "source": [
    "loss_rasp1, accuracy_rasp1=model.evaluate(val_ds,batch_size=1)\n",
    "print(f'Accuracy of rasberrypi--1 trained model on unseen data {accuracy_rasp1}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mudda\\AppData\\Local\\Temp\\tmpxfzffv4_\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "os.mkdir('./checkpoints/rasp1_model_tflite/');\n",
    "# Save the model.\n",
    "with open('./checkpoints/rasp1_model_tflite/model_rasp1.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dfbb260131b2363d2b24945f21daed0db11f3cc372f7d9e8ad1249756cc7056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
