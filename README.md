
# Brain Tumor Detection from MRI using Federated Learning

Privacy-preserving brain-tumor classification on MRI images using a simple CNN and a **federated learning (FL)** workflow that simulates two clients (Raspberry Pi 1 & 2). The global model is updated by averaging client weightsâ€”improving generalization on unseen data without centralizing patient data. 

---

## âœ¨ Highlights

* **Federated training loop:** main model â†’ distribute weights â†’ train clients â†’ average weights â†’ update global model. 
* **Lightweight CNN:** 3Ã—Conv + MaxPool backbone (ReLU), dense head; binary cross-entropy, Adam optimizer. 
* **Edge focus:** TensorFlow/Keras workflow with export to **TFLite** for embedded devices. 
* **Results (indicative):** Main training acc ~**88%**; Client eval on unseen data up to **+9%** after FL weight averaging (RPi1 ~89%, RPi2 ~80%). 

---

## ğŸ§  Problem & Approach

Centralized medical image sharing is restricted; FL keeps data local and only shares **model updates**. We train a baseline CNN on a main split, push weights to two â€œclientsâ€ (Raspberry Pi 1 & 2), train locally, **average** client weights, and update the global model. Evaluate on **unseen** data to assess generalization. 

---

## ğŸ“š Dataset

* **Brain MRI** (binary labels: *tumor yes/no*), **253** images (â‰ˆ155 yes / 98 no).
* Splits: ~60% main model; ~20% RPi1; ~20% RPi2; labels saved to CSV (e.g., `main_data.csv`, `rasp1_data.csv`, `rasp2_data.csv`).
* **Augmentation:** horizontal flips, random rotations (~20%) to balance/regularize.
* GANs were explored but not used due to very small dataset; classic augmentation performed better here. 

> âš ï¸ Please verify license/usage permissions for the original dataset source before redistribution.

---

## ğŸ—ï¸ Project Structure (suggested)

```
repo-root/
â”œâ”€ data/
â”‚  â”œâ”€ main/         # images for main model
â”‚  â”œâ”€ rasp1/        # images for client 1
â”‚  â””â”€ rasp2/        # images for client 2
â”œâ”€ labels/
â”‚  â”œâ”€ main_data.csv
â”‚  â”œâ”€ rasp1_data.csv
â”‚  â””â”€ rasp2_data.csv
â”œâ”€ src/
â”‚  â”œâ”€ models.py           # get_model(), simple vs extra_dense_CNN
â”‚  â”œâ”€ data.py             # loaders/augmentations
â”‚  â”œâ”€ train_main.py       # trains baseline (global init)
â”‚  â”œâ”€ train_client.py     # trains a client from given init weights
â”‚  â”œâ”€ federated.py        # weight avg & global update
â”‚  â”œâ”€ evaluate.py         # eval on unseen sets (per client)
â”‚  â””â”€ export_tflite.py    # TFLite export for edge
â”œâ”€ notebooks/             # (optional) experiment notebooks
â”œâ”€ results/               # metrics, plots
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âš™ï¸ Setup

```bash
# Python 3.10+ recommended
python -m venv .venv
source .venv/bin/activate   # on Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

**requirements.txt (example)**

```
tensorflow>=2.12
numpy
pandas
scikit-learn
matplotlib
```

---

## ğŸš€ Usage

### 1) Prepare data & labels

Place images under `data/` as shown above and generate CSV label files (`labels/*.csv`) with file path and binary label (0/1). 

### 2) Train the main (global-init) model

```bash
python src/train_main.py \
  --data_dir data/main \
  --labels labels/main_data.csv \
  --epochs 10 \
  --out results/main
```

* Saves baseline weights: `results/main/main_weights.h5`. 

### 3) Train client models (local updates)

```bash
# Client 1
python src/train_client.py \
  --init_weights results/main/main_weights.h5 \
  --data_dir data/rasp1 \
  --labels labels/rasp1_data.csv \
  --model_variant extra_dense_CNN \
  --epochs 10 \
  --out results/rasp1

# Client 2
python src/train_client.py \
  --init_weights results/main/main_weights.h5 \
  --data_dir data/rasp2 \
  --labels labels/rasp2_data.csv \
  --model_variant extra_dense_CNN \
  --epochs 10 \
  --out results/rasp2
```

* Produces `rasp1_weights.h5`, `rasp2_weights.h5`. 

### 4) Federated averaging & global update

```bash
python src/federated.py \
  --client_weights results/rasp1/rasp1_weights.h5 results/rasp2/rasp2_weights.h5 \
  --global_init results/main/main_weights.h5 \
  --out results/global/global_weights.h5
```

* Averages client weights and updates the global model. 

### 5) Evaluate on unseen data (per client)

```bash
python src/evaluate.py \
  --weights results/global/global_weights.h5 \
  --data_dir data/rasp1_unseen \
  --labels labels/rasp1_unseen.csv \
  --out results/eval_rasp1

python src/evaluate.py \
  --weights results/global/global_weights.h5 \
  --data_dir data/rasp2_unseen \
  --labels labels/rasp2_unseen.csv \
  --out results/eval_rasp2
```

* Expect improved generalization for clients after FL (e.g., â‰ˆ+9% in reported experiments). 

### 6) Export to TFLite (optional)

```bash
python src/export_tflite.py \
  --weights results/global/global_weights.h5 \
  --out results/global/model.tflite
```

* For embedded/edge deployment. 

---

## ğŸ“ˆ Indicative Results

* **Main model (train acc):** ~**88%**
* **Client eval on unseen data:**

  * RPi1: ~**89%** after FL update vs ~80% before
  * RPi2: ~**80%** (varies by split/seed)
* Small dataset â†’ overfitting risks; keep epochs modest and use augmentation. 

---

## ğŸ§© Model Details

* **Backbone:** 3 conv blocks (8â†’16â†’32 filters), MaxPool, Flatten, Dense(32), Dense(1).
* **Loss/Opt:** BinaryCrossentropy + Adam.
* **Client variant:** adds extra conv/dense layers; earlier layers frozen for transfer learning. 

---

## âš ï¸ Limitations & Notes

* **Data scarcity/class imbalance** can hurt stability; consider stronger augmentation or careful re-splits.
* Client data skew (e.g., more â€œno-tumorâ€ samples on a client) may bias global updates.
* Some devices may lack compute for on-device training. 

---

## ğŸ›£ï¸ Roadmap

* [ ] Add stratified splits and reproducible seeds
* [ ] Track metrics with TensorBoard and save ROC/PR curves
* [ ] Experiment with **FedAvg** variants and differential privacy
* [ ] Evaluate lightweight pretrained backbones (e.g., MobileNet-V2)
* [ ] Improve TFLite quantization (int8) and measure latency on edge 

---

## ğŸ“œ Citation / Reference

If you use this repository or build upon the reported setup/results, please cite or reference the accompanying write-up/presentation for methodology and metrics. 

---

## ğŸ“ License

Add your preferred license (e.g., MIT) here. Make sure the datasetâ€™s license permits your intended use/distribution.

---

## ğŸ™ Acknowledgments

Thanks to the collaborators and prior work on federated learning and medical imaging referenced in the project write-up. 


