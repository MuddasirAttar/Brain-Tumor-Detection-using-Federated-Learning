{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mudda\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"\"\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=10\n",
    "im_height, im_width = 224, 224  ## Image input resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "###### Function to Get the Model\n",
    "\n",
    "def GetModel(type='simple',im_height=224,im_width=224, compile=True):\n",
    "    tf.keras.backend.reset_uids()\n",
    "    if type=='simple':\n",
    "        model = Sequential([\n",
    "          layers.Rescaling(1./255, input_shape=(im_height, im_width, 3)),\n",
    "          layers.Conv2D(8, 3, padding='valid', activation='relu',name='cnn1'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(16, 3, padding='valid', activation='relu',name='cnn2'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='valid', activation='relu',name='cnn3'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(32, activation='relu',name='dense1'),\n",
    "          layers.Dense(1,name='dense2')\n",
    "        ])\n",
    "    elif type=='extra_dense_cnn':\n",
    "        model = Sequential([\n",
    "          layers.Rescaling(1./255, input_shape=(im_height, im_width, 3)),\n",
    "          layers.Conv2D(8, 3, padding='valid', activation='relu',name='cnn1',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(16, 3, padding='valid', activation='relu',name='cnn2',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='valid', activation='relu',name='cnn3',trainable=False),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='same', activation='relu',name='cnn4',trainable=True),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(32, activation='relu',name='dense1'),\n",
    "          layers.Dense(32, activation='relu',name='dense_post'),\n",
    "          layers.Dense(1,name='dense2')\n",
    "        ])\n",
    "    else:\n",
    "      raise 'Model type is not correct'\n",
    "    if compile:\n",
    "      model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "# model_1=GetModel()\n",
    "# for layer in model_1.layers:\n",
    "#   print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### datagenerator to get the batch of data, It takes file list, batch size and resolution as arguments\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class BrainTumorDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True, do_augmentation=False):\n",
    "        \n",
    "        self.df = df\n",
    "        self.batch_size=batch_size\n",
    "        self.input_size=input_size\n",
    "        self.do_augmentation=do_augmentation\n",
    "        if do_augmentation:  ## We need to augment only the training data here.\n",
    "            self.data_augmentation = tf.keras.Sequential([\n",
    "                layers.RandomFlip(\"horizontal\"),\n",
    "                layers.RandomRotation(0.2),\n",
    "                ])\n",
    "\n",
    "            self.replicate_factor=12\n",
    "        else:\n",
    "            self.replicate_factor=1\n",
    "\n",
    "        self.max_index=len(self.df)//self.batch_size\n",
    "    \n",
    "#     def on_epoch_end(self):\n",
    "#         pass\n",
    "    \n",
    "    def load_image(self,name):\n",
    "        image= tf.keras.preprocessing.image.load_img(name)\n",
    "        image= tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image= tf.image.resize(image,(self.input_size[0],self.input_size[1]))\n",
    "        if self.do_augmentation: # and np.random.rand(1)<0.2:   #0.2 propbality the augmentation happens, we don't want distort all the imagews\n",
    "            image=self.data_augmentation(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index=index%self.max_index\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images=[]\n",
    "        labels=[]\n",
    "        for index, row in batches.iterrows():\n",
    "          images.append(self.load_image(row['filename']))\n",
    "          labels.append(row['labels'])\n",
    "        return np.array(images),np.array(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)*self.replicate_factor // self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine two subModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " cnn1 (Conv2D)               (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cnn2 (Conv2D)               (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn3 (Conv2D)               (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn4 (Conv2D)               (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_post (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,625\n",
      "Trainable params: 702,593\n",
      "Non-trainable params: 6,032\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " cnn1 (Conv2D)               (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cnn2 (Conv2D)               (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn3 (Conv2D)               (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn4 (Conv2D)               (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_post (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,625\n",
      "Trainable params: 702,593\n",
      "Non-trainable params: 6,032\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " cnn1 (Conv2D)               (None, 222, 222, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " cnn2 (Conv2D)               (None, 109, 109, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn3 (Conv2D)               (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " cnn4 (Conv2D)               (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_post (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 708,625\n",
      "Trainable params: 702,593\n",
      "Non-trainable params: 6,032\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n"
     ]
    }
   ],
   "source": [
    "### Model averaging\n",
    "\n",
    "model_avg=GetModel('extra_dense_cnn') ## Get the main model\n",
    "\n",
    "model_rasp1=GetModel('extra_dense_cnn')\n",
    "model_rasp1.load_weights(f'./checkpoints/rasp1_model/model')  ## Get the rasp1 model and load the weights\n",
    "\n",
    "model_rasp2=GetModel('extra_dense_cnn')\n",
    "model_rasp2.load_weights(f'./checkpoints/rasp2_model/model')  ## Get the rasp2 model and load the weights\n",
    "\n",
    "## Compute average weights and set as model weights for average model\n",
    "for layer1,layer2,layer_main in zip(model_rasp1.layers,model_rasp2.layers,model_avg.layers): \n",
    "  wt_rasp1=layer1.get_weights()\n",
    "  wt_rasp2=layer2.get_weights()\n",
    "  if len(wt_rasp1)>0:\n",
    "    wts=[]\n",
    "    for w1,w2 in zip(wt_rasp1, wt_rasp2):\n",
    "      wt=np.stack([w1,w2],axis=1).mean(axis =1)\n",
    "      wts.append(wt)\n",
    "    layer_main.set_weights(wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02086089], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate combined model on unsued data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1058 - accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 1.0000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3993 - accuracy: 0.9000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2181 - accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "### Evaluate rasp1 and federated learned (average model) on rasp1 unseen data\n",
    "df=pd.read_csv('./brain_tumour_dataset/rasp1_data.csv') ## Get the rasp1 specific data\n",
    "train_rasp1,vals_rasp1=train_test_split(df,train_size=0.9, stratify=df['labels'],random_state=19)\n",
    "\n",
    "df=pd.read_csv('./brain_tumour_dataset/rasp2_data.csv') ## Get the rasp1 specific data\n",
    "train_rasp1,vals_rasp2=train_test_split(df,train_size=0.9, stratify=df['labels'],random_state=19)\n",
    "\n",
    "\n",
    "val_ds =  BrainTumorDataset(vals_rasp1,1,input_size=(im_height, im_width,3))\n",
    "loss_avg1, accuracy_avg1=model_avg.evaluate(val_ds,batch_size=1)\n",
    "loss_rasp1, accuracy_rasp1=model_rasp1.evaluate(val_ds,batch_size=1)\n",
    "\n",
    "\n",
    "### Evaluate rasp2 and federated learned (average model) on rasp2 unseen data\n",
    "val_ds =  BrainTumorDataset(vals_rasp2,1,input_size=(im_height, im_width,3))\n",
    "loss_avg2, accuracy_avg2=model_avg.evaluate(val_ds,batch_size=1)\n",
    "loss_rasp2, accuracy_rasp2=model_rasp2.evaluate(val_ds,batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Final Results--------------\n",
      " Accuracy of rasp1 trained model on rasp1 unseen data: 100.0%\n",
      " Accuracy of federated trained model on rasp1 unseen data: 100.0%\n",
      " Accuracy of rasp2 trained model on rasp2 unseen data: 80.0000011920929%\n",
      " Accuracy of federated trained model on rasp2 unseen data: 89.99999761581421%\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------Final Results--------------')\n",
    "print(f' Accuracy of rasp1 trained model on rasp1 unseen data: {accuracy_rasp1*100}%')\n",
    "print(f' Accuracy of federated trained model on rasp1 unseen data: {accuracy_avg1*100}%')\n",
    "\n",
    "print(f' Accuracy of rasp2 trained model on rasp2 unseen data: {accuracy_rasp2*100}%')\n",
    "print(f' Accuracy of federated trained model on rasp2 unseen data: {accuracy_avg2*100}%')\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dfbb260131b2363d2b24945f21daed0db11f3cc372f7d9e8ad1249756cc7056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
